{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "093665c4f87d4c7694794080b46ccbfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b770bb6ae60942b4b4ea5e01335aed22",
              "IPY_MODEL_ec38d75959d54ad3be6bc6fdae950f83",
              "IPY_MODEL_8cb2d11628674b5cb152dc90c3db6747"
            ],
            "layout": "IPY_MODEL_ae6df5065753488ab199bdd1dda66248"
          }
        },
        "b770bb6ae60942b4b4ea5e01335aed22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcbc2f09079f4e2e868cc32cf1c52dfa",
            "placeholder": "​",
            "style": "IPY_MODEL_f24fd515032c4bb9957729b1635feb3d",
            "value": "100%"
          }
        },
        "ec38d75959d54ad3be6bc6fdae950f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e395b069767496f830c7acbb631c9bc",
            "max": 78968,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b83acf6e38c43799db98ea8a34a81c7",
            "value": 78968
          }
        },
        "8cb2d11628674b5cb152dc90c3db6747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3365e2443e2d4bd8b1753425b24d150e",
            "placeholder": "​",
            "style": "IPY_MODEL_77aa4e3e9af54da4aa7ae7f3433ac898",
            "value": " 78968/78968 [00:09&lt;00:00, 6802.67it/s]"
          }
        },
        "ae6df5065753488ab199bdd1dda66248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcbc2f09079f4e2e868cc32cf1c52dfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f24fd515032c4bb9957729b1635feb3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e395b069767496f830c7acbb631c9bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b83acf6e38c43799db98ea8a34a81c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3365e2443e2d4bd8b1753425b24d150e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77aa4e3e9af54da4aa7ae7f3433ac898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1e9affad42c4cb7b80b499c37fcd82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68c8e0b8fd2e4520a6f4493fa3ddfbe6",
              "IPY_MODEL_716a846f67f74da5880184a34469dd36",
              "IPY_MODEL_9195abce19714b11a45d3af0191c7615"
            ],
            "layout": "IPY_MODEL_f37c0b232d1e4d4c9b4b85e2d2ef7860"
          }
        },
        "68c8e0b8fd2e4520a6f4493fa3ddfbe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9909191e94c476f97f288152e069fd3",
            "placeholder": "​",
            "style": "IPY_MODEL_61413a20b4cc4e9ca90462afe91a4115",
            "value": "  0%"
          }
        },
        "716a846f67f74da5880184a34469dd36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a7d667a80f4431894a88a46c0b533dc",
            "max": 1609,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f271ccd77b44676a3a8f04020eadac4",
            "value": 0
          }
        },
        "9195abce19714b11a45d3af0191c7615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09348c23ea1e488da3d9b7f8e1c634d1",
            "placeholder": "​",
            "style": "IPY_MODEL_750c9c4b5108403fbd0e78de83b55006",
            "value": " 0/1609 [00:10&lt;?, ?it/s]"
          }
        },
        "f37c0b232d1e4d4c9b4b85e2d2ef7860": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9909191e94c476f97f288152e069fd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61413a20b4cc4e9ca90462afe91a4115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a7d667a80f4431894a88a46c0b533dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f271ccd77b44676a3a8f04020eadac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09348c23ea1e488da3d9b7f8e1c634d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "750c9c4b5108403fbd0e78de83b55006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTMNacHrIXhs",
        "outputId": "c3a79354-49a9-4799-9d01-f8c179b7f576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "중복 제거 후 데이터 개수: 78968\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "data_dir = os.getenv('HOME')\n",
        "kor_path = \"korean-english-park.train.ko\"\n",
        "eng_path = \"korean-english-park.train.en\"\n",
        "\n",
        "# 데이터 정제 및 토큰화\n",
        "def clean_corpus(kor_path, eng_path):\n",
        "    with open(kor_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        kor = f.read().splitlines()\n",
        "    with open(eng_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        eng = f.read().splitlines()\n",
        "\n",
        "    assert len(kor) == len(eng), \"한국어와 영어 문장의 개수가 일치하지 않습니다.\"\n",
        "\n",
        "    # 병렬 데이터(kor, eng)를 묶어 set으로 중복 제거\n",
        "    corpus_set = set(zip(kor, eng))\n",
        "    # 다시 리스트로 변환하여 중복 제거된 병렬 데이터 리스트를 반환\n",
        "    cleaned_corpus = list(corpus_set)\n",
        "\n",
        "    return cleaned_corpus\n",
        "\n",
        "cleaned_corpus = clean_corpus(kor_path, eng_path)\n",
        "\n",
        "print(f\"중복 제거 후 데이터 개수: {len(cleaned_corpus)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "xv1wkO53V_zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    # 모든 입력을 소문자로 변환\n",
        "    sentence = sentence.lower().strip()\n",
        "    # 알파벳, 문장부호, 한글만 남기고 모두 제거\n",
        "    sentence = re.sub(r\"[^a-zA-Zㄱ-ㅎ가-힣?.!,]+\", \" \", sentence)\n",
        "    # 문장부호 양옆에 공백 추가\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    # 문장 앞뒤의 불필요한 공백 제거\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    return sentence\n"
      ],
      "metadata": {
        "id": "ptde0fH6InAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "import re\n",
        "# Sentencepiece를 활용하여 학습한 tokenizer를 생성합니다.\n",
        "def generate_tokenizer(corpus, vocab_size, lang=\"ko\",\n",
        "                       pad_id=0, bos_id=1, eos_id=2, unk_id=3):\n",
        "    # 학습용 데이터 파일 저장\n",
        "    temp_file = f\"corpus_{lang}.txt\"\n",
        "    with open(temp_file, 'w', encoding='utf-8') as f:\n",
        "        for sentence in corpus:\n",
        "            f.write(f\"{sentence}\\n\")\n",
        "\n",
        "    # SentencePiece 모델 학습\n",
        "    spm.SentencePieceTrainer.Train(\n",
        "        input=temp_file,\n",
        "        model_prefix=f\"tokenizer_{lang}\",\n",
        "        vocab_size=vocab_size,\n",
        "        pad_id=pad_id,\n",
        "        bos_id=bos_id,\n",
        "        eos_id=eos_id,\n",
        "        unk_id=unk_id,\n",
        "        model_type=\"unigram\"\n",
        "    )\n",
        "\n",
        "    # 학습된 SentencePiece 모델 로드\n",
        "    sp = spm.SentencePieceProcessor()\n",
        "    sp.Load(f\"tokenizer_{lang}.model\")\n",
        "\n",
        "    # 임시로 만든 파일 제거\n",
        "    os.remove(temp_file)\n",
        "\n",
        "    return sp\n",
        "\n",
        "SRC_VOCAB_SIZE = TGT_VOCAB_SIZE = 20000\n",
        "\n",
        "eng_corpus = []\n",
        "kor_corpus = []\n",
        "\n",
        "# 정제된 corpus에서 한국어, 영어 말뭉치를 각각 분리\n",
        "for k, e in cleaned_corpus:\n",
        "    kor_corpus.append(preprocess_sentence(k))\n",
        "    eng_corpus.append(preprocess_sentence(e))\n",
        "\n",
        "ko_tokenizer = generate_tokenizer(kor_corpus, SRC_VOCAB_SIZE, \"ko\")\n",
        "en_tokenizer = generate_tokenizer(eng_corpus, TGT_VOCAB_SIZE, \"en\")\n",
        "en_tokenizer.set_encode_extra_options(\"bos:eos\") # 시작 토큰과 끝 토큰을 포함\n",
        "\n",
        "# 토크나이저 예시 사용\n",
        "print(\"한국어 예시:\", ko_tokenizer.encode_as_pieces(\"안녕하세요, 개발자 김민혁입니다!\"))\n",
        "print(\"영어 예시:\", en_tokenizer.encode_as_pieces(\"Hello, I'm Minhyeok Kim, a developer!\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1G0Qxw9IoZv",
        "outputId": "77d104c9-1ea3-4621-deb0-73529e1f4f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한국어 예시: ['▁안', '녕', '하', '세요', ',', '▁개발', '자', '▁김', '민', '혁', '입니다', '!']\n",
            "영어 예시: ['<s>', '▁', 'H', 'ello', ',', '▁', \"I'\", 'm', '▁', 'M', 'in', 'hyeo', 'k', '▁', 'K', 'im', ',', '▁a', '▁developer', '!', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm    # Process 과정을 보기 위해\n",
        "import tensorflow as tf\n",
        "\n",
        "src_corpus = []\n",
        "tgt_corpus = []\n",
        "\n",
        "assert len(kor_corpus) == len(eng_corpus)\n",
        "\n",
        "# 토큰의 길이가 50 이하인 문장만 남깁니다.\n",
        "for idx in tqdm(range(len(kor_corpus))):\n",
        "    max_length = 50\n",
        "    kor_tk_corpus = ko_tokenizer.encode(kor_corpus[idx])\n",
        "    eng_tk_corpus = ko_tokenizer.encode(eng_corpus[idx])\n",
        "\n",
        "    # 한국어만 50개 이하로 설정하면 7만개정도의 데이터, 둘다 설정하면 4만개정도가 나온다\n",
        "    if ((len(kor_tk_corpus) <= max_length) & (len(eng_tk_corpus) <= max_length)):\n",
        "        src_corpus.append(kor_tk_corpus)\n",
        "        tgt_corpus.append(eng_tk_corpus)\n",
        "\n",
        "# 패딩처리를 완료하여 학습용 데이터를 완성합니다.\n",
        "enc_train = tf.keras.preprocessing.sequence.pad_sequences(src_corpus, padding='post')\n",
        "dec_train = tf.keras.preprocessing.sequence.pad_sequences(tgt_corpus, padding='post')\n",
        "print(enc_train.shape)\n",
        "print(dec_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "093665c4f87d4c7694794080b46ccbfb",
            "b770bb6ae60942b4b4ea5e01335aed22",
            "ec38d75959d54ad3be6bc6fdae950f83",
            "8cb2d11628674b5cb152dc90c3db6747",
            "ae6df5065753488ab199bdd1dda66248",
            "dcbc2f09079f4e2e868cc32cf1c52dfa",
            "f24fd515032c4bb9957729b1635feb3d",
            "2e395b069767496f830c7acbb631c9bc",
            "3b83acf6e38c43799db98ea8a34a81c7",
            "3365e2443e2d4bd8b1753425b24d150e",
            "77aa4e3e9af54da4aa7ae7f3433ac898"
          ]
        },
        "id": "Cq6Y7C6QIqkT",
        "outputId": "5f1d22c8-0a3a-46bc-9d19-5f37364eb5f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/78968 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "093665c4f87d4c7694794080b46ccbfb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(51509, 50)\n",
            "(51509, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(pos, d_model):\n",
        "    def cal_angle(position, i):\n",
        "        return position / np.power(10000, int(i) / d_model)\n",
        "\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i) for i in range(d_model)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
        "    return sinusoid_table\n",
        "\n",
        "print(\"슝=3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATULPGtEIwWQ",
        "outputId": "47b069fd-64a1-4fd8-8ca7-7bd23706c583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.W_q = tf.keras.layers.Dense(d_model)\n",
        "        self.W_k = tf.keras.layers.Dense(d_model)\n",
        "        self.W_v = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.linear = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
        "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
        "        QK = tf.matmul(Q, K, transpose_b=True)\n",
        "\n",
        "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
        "\n",
        "        if mask is not None: scaled_qk += (mask * -1e9)\n",
        "\n",
        "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
        "        out = tf.matmul(attentions, V)\n",
        "\n",
        "        return out, attentions\n",
        "\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        split_x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
        "\n",
        "        return split_x\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "        combined_x = tf.reshape(combined_x, (batch_size, -1, self.d_model))\n",
        "\n",
        "        return combined_x\n",
        "\n",
        "\n",
        "    def call(self, Q, K, V, mask):\n",
        "        WQ = self.W_q(Q)\n",
        "        WK = self.W_k(K)\n",
        "        WV = self.W_v(V)\n",
        "\n",
        "        WQ_splits = self.split_heads(WQ)\n",
        "        WK_splits = self.split_heads(WK)\n",
        "        WV_splits = self.split_heads(WV)\n",
        "\n",
        "        out, attention_weights = self.scaled_dot_product_attention(\n",
        "            WQ_splits, WK_splits, WV_splits, mask)\n",
        "\n",
        "        out = self.combine_heads(out)\n",
        "        out = self.linear(out)\n",
        "\n",
        "        return out, attention_weights"
      ],
      "metadata": {
        "id": "bYd8EhkdJBk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PoswiseFeedForwardNet, self).__init__()\n",
        "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
        "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def call(self, x):\n",
        "        out = self.w_1(x)\n",
        "        out = self.w_2(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "print(\"슝=3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PmA8PigJG-1",
        "outputId": "5ab9898d-6f43-4fd5-85f3-185d9e6cdccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
        "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
        "\n",
        "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    def call(self, x, mask):\n",
        "\n",
        "        \"\"\"\n",
        "        Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        out = self.norm_1(x)\n",
        "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        \"\"\"\n",
        "        Position-Wise Feed Forward Network\n",
        "        \"\"\"\n",
        "        residual = out\n",
        "        out = self.norm_2(out)\n",
        "        out = self.ffn(out)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        return out, enc_attn\n",
        "\n",
        "print(\"슝=3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUU0obwtJHD3",
        "outputId": "06bade26-6676-45b8-e33f-5e8f6d2b1a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
        "\n",
        "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
        "\n",
        "        \"\"\"\n",
        "        Masked Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        out = self.norm_1(x)\n",
        "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        \"\"\"\n",
        "        Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = out\n",
        "        out = self.norm_2(out)\n",
        "        out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, causality_mask)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        \"\"\"\n",
        "        Position-Wise Feed Forward Network\n",
        "        \"\"\"\n",
        "        residual = out\n",
        "        out = self.norm_3(out)\n",
        "        out = self.ffn(out)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        return out, dec_attn, dec_enc_attn"
      ],
      "metadata": {
        "id": "rfcX66_uJQl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 d_model,\n",
        "                 n_heads,\n",
        "                 d_ff,\n",
        "                 dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout)\n",
        "                        for _ in range(n_layers)]\n",
        "\n",
        "    def call(self, x, mask):\n",
        "        out = x\n",
        "\n",
        "        enc_attns = list()\n",
        "        for i in range(self.n_layers):\n",
        "            out, enc_attn = self.enc_layers[i](out, mask)\n",
        "            enc_attns.append(enc_attn)\n",
        "\n",
        "        return out, enc_attns\n",
        "\n",
        "print(\"슝=3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8P8rOejJQof",
        "outputId": "5294938f-5e29-4324-da7c-dd2d3c90fa37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 d_model,\n",
        "                 n_heads,\n",
        "                 d_ff,\n",
        "                 dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout)\n",
        "                            for _ in range(n_layers)]\n",
        "\n",
        "\n",
        "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
        "        out = x\n",
        "\n",
        "        dec_attns = list()\n",
        "        dec_enc_attns = list()\n",
        "        for i in range(self.n_layers):\n",
        "            out, dec_attn, dec_enc_attn = \\\n",
        "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
        "\n",
        "            dec_attns.append(dec_attn)\n",
        "            dec_enc_attns.append(dec_enc_attn)\n",
        "\n",
        "        return out, dec_attns, dec_enc_attns\n",
        "\n",
        "print(\"슝=3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-Qg_aNVJQrT",
        "outputId": "db0cfd1e-0cb0-40cb-b983-13362150a4b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def generate_causality_mask(src_len, tgt_len):\n",
        "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
        "    return tf.cast(mask, tf.float32)\n",
        "\n",
        "def generate_masks(src, tgt):\n",
        "    enc_mask = generate_padding_mask(src)\n",
        "    dec_enc_mask = generate_padding_mask(src)\n",
        "    dec_mask = generate_padding_mask(tgt)\n",
        "\n",
        "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
        "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
        "\n",
        "    return enc_mask, dec_enc_mask, dec_mask"
      ],
      "metadata": {
        "id": "nYKD88GvLIQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                    n_layers,\n",
        "                    d_model,\n",
        "                    n_heads,\n",
        "                    d_ff,\n",
        "                    src_vocab_size,\n",
        "                    tgt_vocab_size,\n",
        "                    pos_len,\n",
        "                    dropout=0.2,\n",
        "                    shared=True):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model = tf.cast(d_model, tf.float32)\n",
        "\n",
        "        self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
        "        self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
        "\n",
        "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
        "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
        "\n",
        "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
        "\n",
        "        self.shared = shared\n",
        "\n",
        "        if shared: self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
        "\n",
        "    def embedding(self, emb, x):\n",
        "        seq_len = x.shape[1]\n",
        "        out = emb(x)\n",
        "\n",
        "        if self.shared: out *= tf.math.sqrt(self.d_model)\n",
        "\n",
        "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
        "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
        "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
        "\n",
        "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
        "\n",
        "        dec_out, dec_attns, dec_enc_attns = \\\n",
        "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
        "\n",
        "        logits = self.fc(dec_out)\n",
        "\n",
        "        return logits, enc_attns, dec_attns, dec_enc_attns"
      ],
      "metadata": {
        "id": "rvlxeiruJcP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "n_layers = 2\n",
        "d_model = 512\n",
        "n_heads = 8\n",
        "d_ff = 1024\n",
        "src_vocab_size = tgt_vocab_size = 20000\n",
        "pos_len = 256\n",
        "\n",
        "transformer = Transformer(\n",
        "    n_layers, d_model, n_heads, d_ff, src_vocab_size, tgt_vocab_size, pos_len)"
      ],
      "metadata": {
        "id": "RU72Ewo3JhSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(LearningRateScheduler, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = step ** -0.5\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "learning_rate = LearningRateScheduler(512)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98,\n",
        "                                     epsilon=1e-9)\n",
        "\n",
        "print(\"슝=3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW_xwsWhJrY_",
        "outputId": "cbb83a6b-cfba-47b0-8dfc-1aa30db8c998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "슝=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    # Masking 되지 않은 입력의 개수로 Scaling하는 과정\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "GGgHDORBJ389"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Step 함수 정의\n",
        "@tf.function()\n",
        "def train_step(src, tgt, model, optimizer):\n",
        "    gold = tgt[:, 1:]\n",
        "    loss = 0\n",
        "\n",
        "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
        "\n",
        "    # 계산된 loss에 tf.GradientTape()를 적용해 학습을 진행합니다.\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
        "        model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
        "        loss = loss_function(gold, predictions[:, :-1])\n",
        "\n",
        "    variables = model.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return loss, enc_attns, dec_attns, dec_enc_attns"
      ],
      "metadata": {
        "id": "PFBhVM-AKA84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = len(enc_train)\n",
        "steps_per_epoch = len(enc_train) // BATCH_SIZE\n",
        "\n",
        "# tf.data를 사용하여 배치 데이터를 만들기\n",
        "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# 데이터셋의 크기 확인\n",
        "for enc, dec in dataset.take(1):\n",
        "    print(enc.shape, dec.shape)  # 예: (32, max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0eFeKF8KG-4",
        "outputId": "1e4f40e3-581d-4be4-a857-d92e38949ab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 50) (32, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Attention 시각화 함수"
      ],
      "metadata": {
        "id": "rOlic34OKTmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention 시각화 함수\n",
        "import matplotlib.pyplot as plt\n",
        "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
        "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
        "        import seaborn\n",
        "        seaborn.heatmap(data,\n",
        "                        square=True,\n",
        "                        vmin=0.0, vmax=1.0,\n",
        "                        cbar=False, ax=ax,\n",
        "                        xticklabels=x,\n",
        "                        yticklabels=y)\n",
        "\n",
        "    for layer in range(0, 2, 1):\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
        "        print(\"Encoder Layer\", layer + 1)\n",
        "        for h in range(4):\n",
        "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
        "        plt.show()\n",
        "\n",
        "    for layer in range(0, 2, 1):\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
        "        print(\"Decoder Self Layer\", layer+1)\n",
        "        for h in range(4):\n",
        "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Decoder Src Layer\", layer+1)\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
        "        for h in range(4):\n",
        "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "z6Rv2B04KQjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 번역을 생성하는 함수구현"
      ],
      "metadata": {
        "id": "z6WBHIDPKfJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 번역 생성 함수\n",
        "\n",
        "def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    pieces = src_tokenizer.encode_as_pieces(sentence)\n",
        "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
        "\n",
        "    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
        "                                                           maxlen=enc_train.shape[-1],\n",
        "                                                           padding='post')\n",
        "\n",
        "    ids = []\n",
        "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n",
        "    for i in range(dec_train.shape[-1]):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
        "        generate_masks(_input, output)\n",
        "\n",
        "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
        "        model(_input,\n",
        "              output,\n",
        "              enc_padding_mask,\n",
        "              combined_mask,\n",
        "              dec_padding_mask)\n",
        "\n",
        "        predicted_id = \\\n",
        "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
        "\n",
        "        if tgt_tokenizer.eos_id() == predicted_id:\n",
        "            result = tgt_tokenizer.decode_ids(ids)\n",
        "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
        "\n",
        "        ids.append(predicted_id)\n",
        "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
        "\n",
        "    result = tgt_tokenizer.decode_ids(ids)\n",
        "\n",
        "    return pieces, result, enc_attns, dec_attns, dec_enc_attns"
      ],
      "metadata": {
        "id": "d5b1eM98KY0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 번역 생성 및 Attention 시각화 결합하기"
      ],
      "metadata": {
        "id": "c74SmLclLV1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention=True):\n",
        "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
        "    evaluate(sentence, model, src_tokenizer, tgt_tokenizer)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    if plot_attention:\n",
        "        visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)"
      ],
      "metadata": {
        "id": "cFXhAeTgKtFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 훈련"
      ],
      "metadata": {
        "id": "4wSCu-ZPLqLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "EPOCHS = 1\n",
        "examples = [\n",
        "    \"오바마는 대통령이다.\",\n",
        "    \"시민들은 도시 속에 산다.\",\n",
        "    \"커피는 필요 없다.\",\n",
        "    \"일곱 명의 사망자가 발생했다.\"\n",
        "]\n",
        "\n",
        "# 학습 루프\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "\n",
        "    t = tqdm(dataset)  # 배치 단위로 데이터셋에서 가져오기\n",
        "\n",
        "    for (batch, (enc_batch, dec_batch)) in enumerate(t):\n",
        "        # train_step 함수 호출\n",
        "        batch_loss, enc_attns, dec_attns, dec_enc_attns = train_step(enc_batch, dec_batch, transformer, optimizer)\n",
        "\n",
        "        # 손실 합계 계산\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        # 진행 상황 및 손실 표시\n",
        "        t.set_description_str(f'Epoch {epoch + 1}')\n",
        "        t.set_postfix_str(f'Loss {total_loss.numpy() / (batch + 1):.4f}')\n",
        "\n",
        "    # Epoch 마다 예문 번역 확인\n",
        "    print(f'Epoch {epoch + 1} 번역 결과:')\n",
        "    for example in examples:\n",
        "        pieces, translation, _, _, _ = evaluate(example, transformer, ko_tokenizer, en_tokenizer)\n",
        "        print(f'입력: {example}')\n",
        "        print(f'번역: {translation}')\n",
        "\n",
        "    print(f'Epoch {epoch + 1} 완료, 평균 손실: {total_loss.numpy() / len(dataset):.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787,
          "referenced_widgets": [
            "d1e9affad42c4cb7b80b499c37fcd82b",
            "68c8e0b8fd2e4520a6f4493fa3ddfbe6",
            "716a846f67f74da5880184a34469dd36",
            "9195abce19714b11a45d3af0191c7615",
            "f37c0b232d1e4d4c9b4b85e2d2ef7860",
            "e9909191e94c476f97f288152e069fd3",
            "61413a20b4cc4e9ca90462afe91a4115",
            "0a7d667a80f4431894a88a46c0b533dc",
            "7f271ccd77b44676a3a8f04020eadac4",
            "09348c23ea1e488da3d9b7f8e1c634d1",
            "750c9c4b5108403fbd0e78de83b55006"
          ]
        },
        "id": "i8leOlQkKtIh",
        "outputId": "44ac9777-b49e-4f72-c2bd-e70835480bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1609 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1e9affad42c4cb7b80b499c37fcd82b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "in user code:\n\n    File \"<ipython-input-17-110cee77b189>\", line 16, in train_step  *\n        optimizer.apply_gradients(zip(gradients, variables))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\", line 282, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\", line 351, in apply\n        self._backend_apply_gradients(grads, trainable_variables)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\", line 406, in _backend_apply_gradients\n        grads, trainable_variables, self.learning_rate\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\", line 512, in learning_rate\n        return self._get_current_learning_rate()\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\", line 589, in _get_current_learning_rate\n        return self._learning_rate(self.iterations)\n    File \"<ipython-input-15-794e476b21ed>\", line 8, in __call__\n        arg1 = step ** -0.5\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py\", line 446, in __pow__\n        return value.__pow__(self._convert_to_tensor(other, dtype=value.dtype))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py\", line 54, in _convert_to_tensor\n        return convert_to_tensor(value, dtype=dtype)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py\", line 113, in convert_to_tensor\n        return tf.convert_to_tensor(x, dtype=dtype)\n\n    TypeError: Expected int64, but got -0.5 of type 'float'.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-93c3681448a9>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menc_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# train_step 함수 호출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# 손실 합계 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_fileeufth5dl.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m(src, tgt, model, optimizer)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;31m# Return iterations for compat with tf.keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;31m# Apply gradient updates.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0;31m# Apply variable constraints after applying gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36m_backend_apply_gradients\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;31m# Run udpate step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             self._backend_update_step(\n\u001b[0;32m--> 406\u001b[0;31m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m             )\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mlearning_rate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_current_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36m_get_current_learning_rate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_schedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateSchedule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         ):\n\u001b[0;32m--> 589\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-794e476b21ed>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0marg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarmup_steps\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36m__pow__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__pow__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pow__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rpow__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py\u001b[0m in \u001b[0;36m_convert_to_tensor\u001b[0;34m(self, value, dtype)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: F811\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"<ipython-input-17-110cee77b189>\", line 16, in train_step  *\n        optimizer.apply_gradients(zip(gradients, variables))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\", line 282, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\", line 351, in apply\n        self._backend_apply_gradients(grads, trainable_variables)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\", line 406, in _backend_apply_gradients\n        grads, trainable_variables, self.learning_rate\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\", line 512, in learning_rate\n        return self._get_current_learning_rate()\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\", line 589, in _get_current_learning_rate\n        return self._learning_rate(self.iterations)\n    File \"<ipython-input-15-794e476b21ed>\", line 8, in __call__\n        arg1 = step ** -0.5\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py\", line 446, in __pow__\n        return value.__pow__(self._convert_to_tensor(other, dtype=value.dtype))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py\", line 54, in _convert_to_tensor\n        return convert_to_tensor(value, dtype=dtype)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/core.py\", line 113, in convert_to_tensor\n        return tf.convert_to_tensor(x, dtype=dtype)\n\n    TypeError: Expected int64, but got -0.5 of type 'float'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#enc_batch, dec_batch\n",
        "print(dec_batch)"
      ],
      "metadata": {
        "id": "wf1_PJxwKtLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "06EDUhmFNQ4Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}